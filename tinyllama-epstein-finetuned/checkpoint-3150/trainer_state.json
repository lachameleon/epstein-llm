{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0793965859468043,
      "grad_norm": 2.2148830890655518,
      "learning_rate": 9.30379746835443e-05,
      "loss": 7.8113330078125,
      "step": 50
    },
    {
      "epoch": 0.1587931718936086,
      "grad_norm": 0.9728765487670898,
      "learning_rate": 0.00018797468354430377,
      "loss": 7.297769775390625,
      "step": 100
    },
    {
      "epoch": 0.23818975784041285,
      "grad_norm": 1.2643409967422485,
      "learning_rate": 0.00028291139240506325,
      "loss": 7.137250366210938,
      "step": 150
    },
    {
      "epoch": 0.3175863437872172,
      "grad_norm": 1.254591464996338,
      "learning_rate": 0.00029588903743315507,
      "loss": 7.042655029296875,
      "step": 200
    },
    {
      "epoch": 0.39698292973402144,
      "grad_norm": 1.2084978818893433,
      "learning_rate": 0.00029087566844919786,
      "loss": 6.99340576171875,
      "step": 250
    },
    {
      "epoch": 0.4763795156808257,
      "grad_norm": 1.229156732559204,
      "learning_rate": 0.00028586229946524065,
      "loss": 6.945512084960938,
      "step": 300
    },
    {
      "epoch": 0.55577610162763,
      "grad_norm": 1.3278619050979614,
      "learning_rate": 0.0002808489304812834,
      "loss": 6.87389892578125,
      "step": 350
    },
    {
      "epoch": 0.6351726875744343,
      "grad_norm": 2.09529709815979,
      "learning_rate": 0.00027583556149732616,
      "loss": 6.845098266601562,
      "step": 400
    },
    {
      "epoch": 0.7145692735212386,
      "grad_norm": 1.162826418876648,
      "learning_rate": 0.00027082219251336895,
      "loss": 6.836253051757812,
      "step": 450
    },
    {
      "epoch": 0.7939658594680429,
      "grad_norm": 1.7856515645980835,
      "learning_rate": 0.00026580882352941174,
      "loss": 6.790972290039062,
      "step": 500
    },
    {
      "epoch": 0.8733624454148472,
      "grad_norm": 1.0448341369628906,
      "learning_rate": 0.0002607954545454545,
      "loss": 6.783919677734375,
      "step": 550
    },
    {
      "epoch": 0.9527590313616514,
      "grad_norm": 1.2746527194976807,
      "learning_rate": 0.0002557820855614973,
      "loss": 6.74372802734375,
      "step": 600
    },
    {
      "epoch": 1.0317586343787217,
      "grad_norm": 0.9762573838233948,
      "learning_rate": 0.0002507687165775401,
      "loss": 6.80138427734375,
      "step": 650
    },
    {
      "epoch": 1.111155220325526,
      "grad_norm": 1.0766390562057495,
      "learning_rate": 0.0002457553475935829,
      "loss": 6.713706665039062,
      "step": 700
    },
    {
      "epoch": 1.1905518062723304,
      "grad_norm": 1.5280882120132446,
      "learning_rate": 0.00024074197860962564,
      "loss": 6.6685986328125,
      "step": 750
    },
    {
      "epoch": 1.2699483922191346,
      "grad_norm": 1.7530767917633057,
      "learning_rate": 0.00023572860962566843,
      "loss": 6.725615234375,
      "step": 800
    },
    {
      "epoch": 1.3493449781659388,
      "grad_norm": 1.0622074604034424,
      "learning_rate": 0.00023071524064171122,
      "loss": 6.703662719726562,
      "step": 850
    },
    {
      "epoch": 1.4287415641127432,
      "grad_norm": 1.0529228448867798,
      "learning_rate": 0.00022570187165775398,
      "loss": 6.637001342773438,
      "step": 900
    },
    {
      "epoch": 1.5081381500595474,
      "grad_norm": 1.7144129276275635,
      "learning_rate": 0.00022068850267379676,
      "loss": 6.686971435546875,
      "step": 950
    },
    {
      "epoch": 1.5875347360063516,
      "grad_norm": 1.3873200416564941,
      "learning_rate": 0.00021567513368983955,
      "loss": 6.7185498046875,
      "step": 1000
    },
    {
      "epoch": 3.333465660976578,
      "grad_norm": 0.853554368019104,
      "learning_rate": 0.0002106617647058823,
      "loss": 6.64152587890625,
      "step": 1050
    },
    {
      "epoch": 3.4922588328701867,
      "grad_norm": 0.9382859468460083,
      "learning_rate": 0.00020564839572192512,
      "loss": 6.613890991210938,
      "step": 1100
    },
    {
      "epoch": 3.651052004763795,
      "grad_norm": 1.0767990350723267,
      "learning_rate": 0.0002006350267379679,
      "loss": 6.681602783203125,
      "step": 1150
    },
    {
      "epoch": 3.8098451766574035,
      "grad_norm": 0.7878811955451965,
      "learning_rate": 0.0001956216577540107,
      "loss": 6.6588067626953125,
      "step": 1200
    },
    {
      "epoch": 3.9686383485510124,
      "grad_norm": 0.9671106338500977,
      "learning_rate": 0.00019060828877005346,
      "loss": 6.631044311523437,
      "step": 1250
    },
    {
      "epoch": 4.127034537514887,
      "grad_norm": 1.093563437461853,
      "learning_rate": 0.00018559491978609624,
      "loss": 6.614917602539062,
      "step": 1300
    },
    {
      "epoch": 4.285827709408496,
      "grad_norm": 1.0501011610031128,
      "learning_rate": 0.00018058155080213903,
      "loss": 6.613800048828125,
      "step": 1350
    },
    {
      "epoch": 4.444620881302104,
      "grad_norm": 0.8489177227020264,
      "learning_rate": 0.0001755681818181818,
      "loss": 6.58972900390625,
      "step": 1400
    },
    {
      "epoch": 4.603414053195713,
      "grad_norm": 0.917880117893219,
      "learning_rate": 0.00017055481283422458,
      "loss": 6.585474853515625,
      "step": 1450
    },
    {
      "epoch": 4.7622072250893215,
      "grad_norm": 0.9473081827163696,
      "learning_rate": 0.00016554144385026736,
      "loss": 6.581447143554687,
      "step": 1500
    },
    {
      "epoch": 4.9210003969829295,
      "grad_norm": 0.8658047914505005,
      "learning_rate": 0.00016052807486631012,
      "loss": 6.612150268554688,
      "step": 1550
    },
    {
      "epoch": 5.079396585946804,
      "grad_norm": 1.1906020641326904,
      "learning_rate": 0.00015551470588235294,
      "loss": 6.564219970703125,
      "step": 1600
    },
    {
      "epoch": 5.238189757840413,
      "grad_norm": 1.3664405345916748,
      "learning_rate": 0.00015050133689839572,
      "loss": 6.512674560546875,
      "step": 1650
    },
    {
      "epoch": 5.396982929734022,
      "grad_norm": 1.0390194654464722,
      "learning_rate": 0.00014548796791443848,
      "loss": 6.553822021484375,
      "step": 1700
    },
    {
      "epoch": 5.55577610162763,
      "grad_norm": 1.3073437213897705,
      "learning_rate": 0.00014047459893048127,
      "loss": 6.517490844726563,
      "step": 1750
    },
    {
      "epoch": 5.714569273521239,
      "grad_norm": 0.9219369888305664,
      "learning_rate": 0.00013546122994652406,
      "loss": 6.58367431640625,
      "step": 1800
    },
    {
      "epoch": 5.873362445414847,
      "grad_norm": 1.0838003158569336,
      "learning_rate": 0.00013044786096256682,
      "loss": 6.594120483398438,
      "step": 1850
    },
    {
      "epoch": 6.031758634378722,
      "grad_norm": 1.234140396118164,
      "learning_rate": 0.0001254344919786096,
      "loss": 6.547242431640625,
      "step": 1900
    },
    {
      "epoch": 6.19055180627233,
      "grad_norm": 1.191261887550354,
      "learning_rate": 0.0001204211229946524,
      "loss": 6.522792358398437,
      "step": 1950
    },
    {
      "epoch": 6.349344978165939,
      "grad_norm": 0.9209516048431396,
      "learning_rate": 0.00011540775401069518,
      "loss": 6.50240234375,
      "step": 2000
    },
    {
      "epoch": 6.508138150059548,
      "grad_norm": 0.9971117973327637,
      "learning_rate": 0.00011039438502673796,
      "loss": 6.520127563476563,
      "step": 2050
    },
    {
      "epoch": 6.666931321953156,
      "grad_norm": 1.3375729322433472,
      "learning_rate": 0.00010538101604278074,
      "loss": 6.545632934570312,
      "step": 2100
    },
    {
      "epoch": 6.8257244938467645,
      "grad_norm": 1.25674569606781,
      "learning_rate": 0.00010036764705882351,
      "loss": 6.511025390625,
      "step": 2150
    },
    {
      "epoch": 6.984517665740373,
      "grad_norm": 1.202010989189148,
      "learning_rate": 9.535427807486631e-05,
      "loss": 6.54970703125,
      "step": 2200
    },
    {
      "epoch": 7.142913854704248,
      "grad_norm": 1.0170197486877441,
      "learning_rate": 9.034090909090908e-05,
      "loss": 6.49872314453125,
      "step": 2250
    },
    {
      "epoch": 7.301707026597857,
      "grad_norm": 1.41182541847229,
      "learning_rate": 8.532754010695186e-05,
      "loss": 6.501796264648437,
      "step": 2300
    },
    {
      "epoch": 7.460500198491465,
      "grad_norm": 1.102301836013794,
      "learning_rate": 8.031417112299464e-05,
      "loss": 6.467081909179687,
      "step": 2350
    },
    {
      "epoch": 7.619293370385074,
      "grad_norm": 1.1654448509216309,
      "learning_rate": 7.530080213903742e-05,
      "loss": 6.533358154296875,
      "step": 2400
    },
    {
      "epoch": 7.7780865422786825,
      "grad_norm": 1.173929214477539,
      "learning_rate": 7.02874331550802e-05,
      "loss": 6.4889593505859375,
      "step": 2450
    },
    {
      "epoch": 7.93687971417229,
      "grad_norm": 1.337776780128479,
      "learning_rate": 6.527406417112299e-05,
      "loss": 6.51190185546875,
      "step": 2500
    },
    {
      "epoch": 8.095275903136166,
      "grad_norm": 1.1807750463485718,
      "learning_rate": 6.026069518716577e-05,
      "loss": 6.485402221679688,
      "step": 2550
    },
    {
      "epoch": 8.254069075029774,
      "grad_norm": 1.1915977001190186,
      "learning_rate": 5.524732620320855e-05,
      "loss": 6.467850952148438,
      "step": 2600
    },
    {
      "epoch": 8.412862246923382,
      "grad_norm": 1.218049168586731,
      "learning_rate": 5.023395721925133e-05,
      "loss": 6.457567749023437,
      "step": 2650
    },
    {
      "epoch": 8.571655418816992,
      "grad_norm": 1.2053401470184326,
      "learning_rate": 4.522058823529411e-05,
      "loss": 6.475690307617188,
      "step": 2700
    },
    {
      "epoch": 8.7304485907106,
      "grad_norm": 1.2721405029296875,
      "learning_rate": 4.02072192513369e-05,
      "loss": 6.49098876953125,
      "step": 2750
    },
    {
      "epoch": 8.889241762604208,
      "grad_norm": 1.372667670249939,
      "learning_rate": 3.519385026737968e-05,
      "loss": 6.515907592773438,
      "step": 2800
    },
    {
      "epoch": 9.047637951568083,
      "grad_norm": 1.1836516857147217,
      "learning_rate": 3.0180481283422457e-05,
      "loss": 6.459091796875,
      "step": 2850
    },
    {
      "epoch": 9.206431123461691,
      "grad_norm": 1.0455775260925293,
      "learning_rate": 2.516711229946524e-05,
      "loss": 6.509469604492187,
      "step": 2900
    },
    {
      "epoch": 9.365224295355299,
      "grad_norm": 0.9802221655845642,
      "learning_rate": 2.015374331550802e-05,
      "loss": 6.487177734375,
      "step": 2950
    },
    {
      "epoch": 9.524017467248909,
      "grad_norm": 1.1465363502502441,
      "learning_rate": 1.51403743315508e-05,
      "loss": 6.4558477783203125,
      "step": 3000
    },
    {
      "epoch": 9.682810639142517,
      "grad_norm": 1.2992907762527466,
      "learning_rate": 1.0127005347593584e-05,
      "loss": 6.46743408203125,
      "step": 3050
    },
    {
      "epoch": 9.841603811036126,
      "grad_norm": 1.1768245697021484,
      "learning_rate": 5.113636363636363e-06,
      "loss": 6.503694458007812,
      "step": 3100
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.6623185873031616,
      "learning_rate": 1.0026737967914437e-07,
      "loss": 6.4508294677734375,
      "step": 3150
    }
  ],
  "logging_steps": 50,
  "max_steps": 3150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 369195047976960.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
